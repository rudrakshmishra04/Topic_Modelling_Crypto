{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code To extract the Reddit Posts using PRAW and PSAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import praw\n",
    "from psaw import PushshiftAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To convert the from timestamp to date format.\n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the Reddit\n",
    "api = PushshiftAPI()\n",
    "reddit = praw.Reddit(\n",
    "    client_id = 'HXb1QVH0dCWerGHgJuPHgA',\n",
    "    client_secret = 'hB9ZG4iZ74NSegVyx6pA7ED-DnA-Tg',\n",
    "    user_agent = 'predictiveAnalytics',\n",
    "    username = 'nqk5398',\n",
    "    password = 'Kunduru1!'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic to be extracted\n",
    "topic = ['CryptoCurrency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the time period between for which the posts are to be extracted.\n",
    "after = int(dt.datetime(2021, 1, 1).timestamp())\n",
    "before = int(dt.datetime(2022, 1, 25).timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary for the data extracted\n",
    "submissions_dict = {\n",
    "        \"id\" : [],\n",
    "        \"url\" : [],\n",
    "        \"title\" : [],\n",
    "        \"score\" : [],\n",
    "        \"comms_num\": [],\n",
    "        \"created\" : [],\n",
    "        \"body\" : [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the posts.\n",
    "post = api.search_submissions(\n",
    "    after=after,\n",
    "    before=before,\n",
    "    filter=['id'],\n",
    "    subreddit=topic,\n",
    "    limit=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to extract the details from the redddit\n",
    "for i in post:\n",
    "    postId = i.d_['id']\n",
    "    postData= reddit.submission(id=postId)\n",
    "\n",
    "    submissions_dict[\"id\"].append(postData.id)\n",
    "    submissions_dict[\"url\"].append(postData.url)\n",
    "    submissions_dict[\"title\"].append(postData.title)\n",
    "    submissions_dict[\"score\"].append(postData.score)\n",
    "    submissions_dict[\"comms_num\"].append(postData.num_comments)\n",
    "    submissions_dict[\"created\"].append(postData.created_utc)\n",
    "    submissions_dict[\"body\"].append(postData.selftext)\n",
    "\n",
    "    postData.comments.replace_more(limit=None)\n",
    "    for comment in postData.comments.list():\n",
    "        submissions_dict[\"title\"].append(\"Comment\")\n",
    "        submissions_dict[\"score\"].append(comment.score)\n",
    "        submissions_dict[\"id\"].append(comment.id)\n",
    "        submissions_dict[\"url\"].append(\"\")\n",
    "        submissions_dict[\"comms_num\"].append(0)\n",
    "        submissions_dict[\"created\"].append(comment.created)\n",
    "        submissions_dict[\"body\"].append(comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a data frame and convert into csv\n",
    "submissions_dict = pd.DataFrame(submissions_dict)\n",
    "submissions_dict['created'] = submissions_dict['created'].apply(lambda x: get_date(x))\n",
    "submissions_dict.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code To extract the Reddit Posts using PMAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the time period between for which the posts are to be extracted.\n",
    "before = int(dt.datetime(2022,1,31,0,0).timestamp())\n",
    "after = int(dt.datetime(2021,10,1,0,0).timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the posts.\n",
    "subreddit=\"CryptoCurrency\"\n",
    "limit=200000\n",
    "redditData = api.search_comments(subreddit=subreddit, limit=limit, before=before, after=after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a data frame and convert into csv\n",
    "redditDataDF = pd.DataFrame(redditData)\n",
    "redditDataDF['created'] = redditDataDF['created_utc'].apply(lambda x: dt.datetime.fromtimestamp(x))\n",
    "redditDataDF.to_csv('redditcomments.csv', header=True, index=False, columns=list(redditDataDF.axes[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
